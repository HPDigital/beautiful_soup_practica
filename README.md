# Web Scraper con BeautifulSoup

Un scraper web moderno y eficiente implementado en Python que utiliza BeautifulSoup4 para extraer y analizar contenido de pÃ¡ginas web. El proyecto estÃ¡ diseÃ±ado para extraer automÃ¡ticamente tÃ­tulos, encabezados, pÃ¡rrafos, tablas, imÃ¡genes y metadatos de cualquier pÃ¡gina web proporcionada.

## ğŸš€ CaracterÃ­sticas Principales

- ExtracciÃ³n automÃ¡tica de contenido web
- Procesamiento de tablas HTML a Excel
- ExtracciÃ³n de metadatos e imÃ¡genes
- Sistema de limpieza de texto
- OrganizaciÃ³n automÃ¡tica de resultados por timestamp
- Sistema completo de logging
- Manejo de errores robusto

## ğŸ“‹ Requisitos Previos

## ğŸ“– InstalaciÃ³n

1. Clona el repositorio:

2. Crea un entorno virtual:

3. Instala las dependencias:

## ğŸ¯ Uso

### Uso BÃ¡sico

### Estructura de Resultados

El scraper genera los siguientes archivos en `output/[timestamp]/`:

- `article_info.json`: InformaciÃ³n general del artÃ­culo
- `clean_text.txt`: Texto extraÃ­do y limpio
- `tables.xlsx`: Tablas encontradas en formato Excel
- `metadata.json`: Metadatos del anÃ¡lisis

## ğŸ“ Estructura del Proyecto

## ğŸ” Funcionalidades Detalladas

### ExtracciÃ³n de Contenido
- TÃ­tulos y encabezados
- PÃ¡rrafos y texto limpio
- Enlaces
- Tablas
- ImÃ¡genes y sus atributos
- Metadatos de la pÃ¡gina

### Procesamiento
- Limpieza automÃ¡tica de texto
- ConversiÃ³n de tablas a Excel
- OrganizaciÃ³n temporal de resultados

### Almacenamiento
- Resultados organizados por timestamp
- MÃºltiples formatos (JSON, Excel, TXT)
- Metadatos completos del anÃ¡lisis

## âš™ï¸ Dependencias Principales

- beautifulsoup4>=4.12.0
- requests>=2.31.0
- pandas>=2.0.0
- lxml>=4.9.0
- openpyxl>=3.1.0

## ğŸ“ Logging

El sistema incluye logging completo que:
- Registra todas las operaciones en `scraping.log`
- Guarda errores y advertencias
- Proporciona trazabilidad completa

## ğŸ”’ Manejo de Errores

El scraper incluye manejo robusto de errores para:
- Conexiones fallidas
- PÃ¡ginas no encontradas
- Contenido malformado
- Errores de parseo
- Problemas de escritura de archivos

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles

## âœ¨ Agradecimientos

- BeautifulSoup4 por su excelente biblioteca de scraping
- Pandas por el manejo de datos
- Requests por la gestiÃ³n de peticiones HTTP
